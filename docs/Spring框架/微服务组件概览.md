微服务组件概览



## 注册中心

注册中心主要用于解耦服务实例与服务名称，使服务调用方只需知晓服务名称即可完成服务调用。它本质上是一个**数据存储服务**，维护着服务名称与服务实例元数据之间的映射关系。

- **服务注册**：服务启动后，会将其自身的信息注册到注册中心。
- **服务发现**：当服务需要调用其他服务时，可通过服务名称向注册中心查询对应的服务实例。
- **健康检查**：服务实例会定期向注册中心发送心跳，以表明其处于可用状态。

ZooKeeper：主要定位是**分布式协调服务**，可以利用它的树形路径存储模型和Watcher机制实现注册中心。

etcd：主要定位是**分布式键值存储**，K8s的服务发现机制的底层存储就是etcd，另外通过DNS实现服务发现。

> 技术选型：ZooKeeper架构复杂；etcd只适合K8s生态；Eureka作为注册中心比较纯粹，但已经停止维护且AP架构强一致性不能保证；现在一般推荐使用Nacos，支持AP/CP两种模式，并且结合了配置管理功能。





## 服务网关

与传统的流量网关 Nginx（又称边缘网关）类似，服务网关（Service Gateway）在微服务架构中承担着系统对外的统一入口角色，负责将外部请求路由并转发至后端的具体微服务实例。

其核心作用是提供**统一的接入点**，实现内外网的解耦。这一目标主要通过**路由转发**机制与注册中心的**服务发现**能力相结合来实现：网关根据服务名称动态获取可用的服务实例列表，完成基于服务逻辑的动态路由，而非依赖固定的 IP 和端口。

此外，服务网关通常还集成多种服务治理功能，如统一的身份认证与权限控制、接口级别的限流熔断、日志监控、协议转换等，从而减轻后端服务的通用逻辑负担，提升系统的安全性与可维护性。





## 远程调用

远程调用 RPC（Remote Procedure Call）框架的核心目标是**封装远程服务调用的底层复杂性**，屏蔽网络通信、数据序列化、传输协议、服务寻址等技术细节，使开发者能够像调用本地方法一样便捷地调用远程服务。

相比于普通的HttpClient调用接口，RPC框架自动处理了多种功能，比如服务发现（通常RPC框架通过插件或者自定义接口联合注册中心使用），序列化与反序列化，负载均衡，异常处理，超时重试，熔断降级等功能。





## 远程调用扩展（Sentinel）

Sentinel 本质上是一个嵌入式的流量治理引擎，它利用 Dubbo、Feign 等 RPC 框架的扩展机制（如 Filter、Interceptor、AOP）进行拦截，在本地实现对 RPC 调用的限流、熔断等控制；同时，它可以配合一个可选的“中心化控制台”（Sentinel Dashboard），实现规则的统一配置与监控，从而达到“本地决策 + 集中管理”的治理模式。





## 注册中心扩展（CAP定理与共识算法）

在分布式系统中，当发生网络分区（P：Partition Tolerance）时，根据 CAP 定理，数据一致性（C：Consistency）和可用性（A：Availability）无法同时满足，系统只能在两者之间做出取舍：

- 如果优先保证**一致性**（C），则必须暂停部分节点的服务，等待数据在所有副本间达成一致后才对外提供服务，这会降低系统的可用性。
- 如果优先保证**可用性**（A），系统在任何分区下都可响应请求，但可能导致不同节点读取到的数据不一致。

注册中心作为微服务架构中的核心基础设施，其设计必须遵循 CAP 理论进行权衡。多数注册中心选择在发生网络分区时优先保障数据一致性（C），从而牺牲部分可用性（A）。

为了实现强一致性，主流注册中心通常采用共识算法（Consensus Algorithm）来协调多个节点之间的数据同步。常见的实现包括：**ZooKeeper** 的 **ZAB 协议**，**etcd** 的 **Raft 协议**。

这些共识算法的核心思想是：在集群中选举出一个 Leader 节点，所有写操作由 Leader 统一处理，并通过“多数派确认”（majority acknowledgment）机制确保数据写入到超过半数的节点后才视为成功，从而保障数据的一致性和容错性。

在网络分区发生时：

- 若 Leader 节点位于**多数派分区**，则该分区可继续提供写服务，保证一致性；
- 若 Leader 位于**少数派分区**，则该分区无法与多数节点通信，无法达成多数派确认，因此会停止处理写请求，以防止数据不一致；
- 少数派分区中的节点也无法选举出新的 Leader，因此整个分区在写操作上表现为不可用。

这种机制确保了在任何时刻，全局数据状态是唯一且一致的（满足 C），但代价是在网络分区期间，部分节点（尤其是少数派分区）无法提供写服务，牺牲了系统的可用性（A）。











END